# ðŸ§  RAG-Powered Document Q&A System

A lightweight Retrieval-Augmented Generation (RAG) system built with FastAPI, LangChain, ChromaDB, and a locally hosted LLM (`EleutherAI/gpt-neo-125M`). This project enables users to upload PDF documents, embed their content, and ask context-aware questions with accurate source citations â€” all without using OpenAI APIs.

---

## ðŸš€ Features

- âœ… Upload and store PDF documents.
- âœ… Extract and chunk text intelligently.
- âœ… Generate embeddings using `all-MiniLM-L6-v2`.
- âœ… Store/retrieve vectors using **ChromaDB**.
- âœ… Run question-answering over embedded documents.
- âœ… Offline local LLM (`gpt-neo-125M`) for inference.
- âœ… Source tracking for generated answers.
- âœ… FastAPI-based backend with interactive Swagger UI.

---

## ðŸ§° Tech Stack

| Component       | Tool/Library                       |
|----------------|------------------------------------|
| Embeddings      | HuggingFace `all-MiniLM-L6-v2`     |
| Vector DB       | `ChromaDB`                         |
| LLM             | `EleutherAI/gpt-neo-125M` (offline)|
| Backend         | `FastAPI`, `Uvicorn`               |
| File parsing    | `PyMuPDF`, `langchain`             |
| TTS (optional)  | `pyttsx3` or `gTTS`                |

---
